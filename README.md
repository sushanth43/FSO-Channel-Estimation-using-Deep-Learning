# FSO-Channel-Estimation-using-Deep-Learning
FSO Channel Estimation using Deep Learning
ğŸš€ Deep Learning-Based Channel Estimation in Free-Space Optical (FSO) Communication ğŸš€

Iâ€™m thrilled to share my current project where Iâ€™m exploring how Bidirectional LSTM models can be used to estimate channel gain in Free-Space Optical (FSO) communication systems â€” a field that blends wireless communication theory, optical impairments, and AI.

ğŸ“Œ Objective:
To develop a deep learning model that can predict the true channel gain (h_true) in FSO systems affected by:

ğŸŒ«ï¸ Weak atmospheric turbulence (Log-normal fading)

ğŸ¯ Pointing error (due to jitter)

ğŸŒ¥ï¸ Visibility-based atmospheric loss (Kim's model)

These channel conditions are dynamic, and accurate estimation is crucial for calculating:

ğŸ“‰ Bit Error Rate (BER)

âš ï¸ Outage Probability

ğŸ› ï¸ What Iâ€™ve Done So Far:
ğŸ”¹ Simulated a dataset of received signals under varying turbulence, pointing errors, and visibility.

ğŸ”¹ Built a Bidirectional LSTM model trained to estimate average channel gain over a time window.

ğŸ”¹ Evaluated the model against traditional estimators:

Maximum Likelihood Estimator (MLE)

Minimum Mean Square Error (MMSE)

Blind Estimator

ğŸ”¹ Computed BER and outage performance using the predicted channel estimates.


ğŸ”§ Still working on improving outage probability estimation, particularly in aligning the LSTM-based results with theoretical (Meijer G-function) and traditional estimators.

ğŸ§  The modelâ€™s performance is close â€” but still needs enhancement to consistently outperform conventional methods under all channel conditions.

ğŸ“Š Analysis So Far:
RÂ² Score: 0.99
Outage probabilities benchmarked with Meijer G-function model
